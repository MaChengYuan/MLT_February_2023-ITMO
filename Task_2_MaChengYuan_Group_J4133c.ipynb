{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "58a9273c-47cb-4baf-a5ae-02bacc4a109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f10f6b63-1e0c-4237-9c1e-03b8a3015edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of Alice’s Adventures in Wonderland, by Lewis Carroll\\n\\nThis eBook is fo'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/mac/Desktop/MLT/alice.txt'\n",
    "with open(filename, encoding='utf-8') as f:\n",
    "    alice_in_wonderland = f.read()\n",
    "alice_in_wonderland[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dfdba6b9-9a6a-4823-a7d7-ae8b0b90c52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDown the Rabbit-Hole\\n\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, '"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile = alice_in_wonderland.split('CHAPTER I.')[2]\n",
    "textfile = textfile.split('THE END')[0]\n",
    "textfile[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "89e61bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer, WhitespaceTokenizer    \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2135a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_text):\n",
    "    lower_input = input_text.lower()\n",
    "    lower_input = re.sub(r\"won\\'t\", \"will not\", lower_input)\n",
    "    lower_input = re.sub(r\"can\\'t\", \"can not\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'re\", \" are\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'s\", \" is\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'d\", \" would\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'ll\", \" will\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'t|n\\'t\", \" not\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'ve\", \" have\", lower_input)\n",
    "    lower_input = re.sub(r\"\\'m\", \" am\", lower_input)\n",
    "    lower_input = re.sub(r\"[^\\w\\s]|_\", \"\", lower_input)\n",
    "    words = lower_input.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_after_sw = [word for word in words if not word in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_tokens = [lemmatizer.lemmatize(word) for word in words_after_sw]\n",
    "    #\"v\" means verb\n",
    "    lemm_tokens = [lemmatizer.lemmatize(word, \"v\") for word in words_after_sw]    \n",
    "    result = \" \".join(lemm_tokens) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0d495f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "chapters = textfile.split('CHAPTER ')\n",
    "chapter_num = 1\n",
    "chapter_list = []\n",
    "for chapter in chapters:\n",
    "    chapter = preprocess(chapter)\n",
    "    chapter = re.sub(r'alice', '', chapter) \n",
    "    chapter_list.append(chapter)\n",
    "chapter_list = np.array(chapter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0cef5640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ii pool tear curiouser curiouser cry  much surprise moment quite forget speak good english im open like largest telescope ever goodbye feet look feet seem almost sight get far oh poor little feet wonder put shoe stock dears im sure shant able shall great deal far trouble must manage best way canbut must kind think  perhaps wont walk way want go let see ill give new pair boot every christmas go plan would manage must go carrier think funny itll seem send present ones feet odd directions look s right foot esq hearthrug near fender s love oh dear nonsense im talk head strike roof hall fact nine feet high take little golden key hurry garden door poor  much could lie one side look garden one eye get hopeless ever sit begin cry ought ashamed say  great girl like might well say go cry way stop moment tell go shed gallons tear large pool round four inch deep reach half hall time hear little patter feet distance hastily dry eye see come white rabbit return splendidly dress pair white kid gloves one hand large fan come trot along great hurry mutter come oh duchess duchess oh wont savage ive keep wait  felt desperate ready ask help one rabbit come near begin low timid voice please sir rabbit start violently drop white kid gloves fan skurried away darkness hard could go  take fan gloves hall hot keep fan time go talk dear dear queer everything today yesterday things go usual wonder ive change night let think get morning almost think remember feel little different im next question world ah thats great puzzle begin think children know age see could change im sure im ada say hair go long ringlets mine doesnt go ringlets im sure cant mabel know sort things oh know little besides shes im andoh dear puzzle ill try know things use know let see four time five twelve four time six thirteen four time seven isoh dear shall never get twenty rate however multiplication table doesnt signify let try geography london capital paris paris capital rome romeno thats wrong im certain must change mabel ill try say doth little cross hand lap say lessons begin repeat voice sound hoarse strange word come use doth little crocodile improve shin tail pour water nile every golden scale cheerfully seem grin neatly spread claw welcome little fish gently smile jaw im sure right word say poor  eye fill tear go must mabel shall go live poky little house next toy play oh ever many lessons learn ive make mind im mabel ill stay itll use put head say come dear shall look say tell first like person ill come ill stay till im somebody elsebut oh dear cry  sudden burst tear wish would put head tire alone say look hand surprise see put one rabbit little white kid gloves talk do think must grow small get go table measure find nearly could guess two feet high go shrink rapidly soon find cause fan hold drop hastily time avoid shrink away altogether narrow escape say  good deal frighten sudden change glad find still existence garden run speed back little door alas little door shut little golden key lie glass table things worse ever think poor child never small never declare bad say word foot slip another moment splash chin salt water first idea somehow fall sea case go back railway say  seaside life come general conclusion wherever go english coast find number bath machine sea children dig sand wooden spade row lodge house behind railway station however soon make pool tear weep nine feet high wish hadnt cry much say  swim try find way shall punish suppose drown tear queer thing sure however everything queer today hear something splash pool little way swim nearer make first think must walrus hippopotamus remember small soon make mouse slip like would use think  speak mouse everything outoftheway think likely talk rate theres harm try begin mouse know way pool tire swim mouse  think must right way speak mouse never do thing remember see brothers latin grammar mouseof mouseto mousea mouseo mouse mouse look rather inquisitively seem wink one little eye say nothing perhaps doesnt understand english think  daresay french mouse come william conqueror knowledge history  clear notion long ago anything happen begin où est chatte first sentence french lessonbook mouse give sudden leap water seem quiver fright oh beg pardon cry  hastily afraid hurt poor animals feel quite forget didnt like cat like cat cry mouse shrill passionate voice would like cat well perhaps say  soothe tone dont angry yet wish could show cat dinah think youd take fancy cat could see dear quiet thing  go half swim lazily pool sit purr nicely fire lick paw wash faceand nice soft thing nurseand shes capital one catch miceoh beg pardon cry  time mouse bristle felt certain must really offend wont talk youd rather indeed cry mouse tremble end tail would talk subject family always hat cat nasty low vulgar things dont let hear name wont indeed say  great hurry change subject conversation youare fondofof dog mouse answer  go eagerly nice little dog near house like show little brighteyed terrier know oh long curly brown hair itll fetch things throw itll sit beg dinner sort thingsi cant remember half themand belong farmer know say useful worth hundred pound say kill rat andoh dear cry  sorrowful tone im afraid ive offend mouse swim away hard could go make quite commotion pool go call softly mouse dear come back wont talk cat dog either dont like mouse hear turn round swim slowly back face quite pale passion  think say low tremble voice let us get shore ill tell history youll understand hate cat dog high time go pool get quite crowd bird animals fall duck dodo lory eaglet several curious creatures  lead way whole party swim shore'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "66003ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are 12 chapters\n",
    "chapter_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "be0ba804",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = list(range(1,13))\n",
    "index = list(range(0,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "02e3e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rabbithole  begin get tire sit sister bank not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ii pool tear curiouser curiouser cry  much sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>iii caucusrace long tale indeed queerlooking p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iv rabbit send little bill white rabbit trot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>v advice caterpillar caterpillar  look time si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>vi pig pepper minute two stand look house wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>vii mad teaparty table set tree front house ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>viii queen croquetground large rosetree stand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ix mock turtle story cant think glad see dear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>x lobster quadrille mock turtle sigh deeply dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>xi steal tarts king queen hearts seat throne a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>xii s evidence cry  quite forget flurry moment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text\n",
       "0       1  rabbithole  begin get tire sit sister bank not...\n",
       "1       2  ii pool tear curiouser curiouser cry  much sur...\n",
       "2       3  iii caucusrace long tale indeed queerlooking p...\n",
       "3       4  iv rabbit send little bill white rabbit trot s...\n",
       "4       5  v advice caterpillar caterpillar  look time si...\n",
       "5       6  vi pig pepper minute two stand look house wond...\n",
       "6       7  vii mad teaparty table set tree front house ma...\n",
       "7       8  viii queen croquetground large rosetree stand ...\n",
       "8       9  ix mock turtle story cant think glad see dear ...\n",
       "9      10  x lobster quadrille mock turtle sigh deeply dr...\n",
       "10     11  xi steal tarts king queen hearts seat throne a...\n",
       "11     12  xii s evidence cry  quite forget flurry moment..."
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = {'index': num, 'text': chapter_list}\n",
    "text_pd = pd.DataFrame(data=texts, index=index)\n",
    "text_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c5b461a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(max_features=3000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "dd0aeed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=3000, stop_words='english')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tfidf.fit(text_pd[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9c235a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(text):\n",
    "    response = vectorizer_tfidf.transform(text)\n",
    "    feature_array = np.array(vectorizer_tfidf.get_feature_names_out())\n",
    "    \n",
    "    return response , feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "65a4a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1956)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf , feature_array = tfidf(text_pd[\"text\"])\n",
    "#text_tfidf = vectorizer_tfidf.transform(text_pd[\"text\"])\n",
    "     \n",
    "tfidf_df = pd.DataFrame(text_tfidf.toarray(), columns=feature_array)  \n",
    "\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "56c7e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absence</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absurd</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptance</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youre</th>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025310</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>0.059245</td>\n",
       "      <td>0.046325</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>0.010906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youve</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022458</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.016570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "abide       0.000000  0.000000  0.000000  0.000000  0.000000  0.022798   \n",
       "able        0.000000  0.032543  0.000000  0.000000  0.000000  0.000000   \n",
       "absence     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "absurd      0.000000  0.000000  0.026744  0.000000  0.000000  0.019580   \n",
       "acceptance  0.000000  0.000000  0.031141  0.000000  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "youre       0.014070  0.000000  0.025310  0.011116  0.059245  0.046325   \n",
       "youth       0.000000  0.000000  0.000000  0.000000  0.145785  0.000000   \n",
       "youve       0.000000  0.000000  0.000000  0.000000  0.015002  0.000000   \n",
       "zealand     0.034621  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "zigzag      0.000000  0.000000  0.000000  0.000000  0.024297  0.000000   \n",
       "\n",
       "                  6         7         8         9         10        11  \n",
       "abide       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "able        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "absence     0.000000  0.000000  0.020212  0.000000  0.000000  0.000000  \n",
       "absurd      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "acceptance  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...              ...       ...       ...       ...       ...       ...  \n",
       "youre       0.007645  0.000000  0.016428  0.007391  0.028252  0.010906  \n",
       "youth       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "youve       0.000000  0.014299  0.000000  0.022458  0.014308  0.016570  \n",
       "zealand     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "zigzag      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[1956 rows x 12 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_word = tfidf_df.T\n",
    "most_frequent_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d8e3a11a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter1\n",
      "think     0.229056\n",
      "eat       0.213768\n",
      "say       0.192889\n",
      "little    0.180834\n",
      "bat       0.178399\n",
      "key       0.157590\n",
      "fall      0.149638\n",
      "like      0.132611\n",
      "way       0.132611\n",
      "door      0.125361\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "chapter2\n",
      "mouse     0.321500\n",
      "say       0.215307\n",
      "pool      0.197508\n",
      "little    0.192643\n",
      "im        0.171925\n",
      "cat       0.160750\n",
      "think     0.158648\n",
      "swim      0.155119\n",
      "dear      0.143051\n",
      "fan       0.139742\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "chapter3\n",
      "say        0.433750\n",
      "mouse      0.384560\n",
      "dodo       0.320932\n",
      "prize      0.186847\n",
      "lory       0.160466\n",
      "know       0.140969\n",
      "dry        0.127230\n",
      "thimble    0.124564\n",
      "bird       0.115368\n",
      "cause      0.106977\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "chapter4\n",
      "little    0.219068\n",
      "window    0.218824\n",
      "rabbit    0.198086\n",
      "say       0.180969\n",
      "grow      0.169353\n",
      "fan       0.164438\n",
      "puppy     0.164118\n",
      "come      0.142870\n",
      "bottle    0.140946\n",
      "gloves    0.140946\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "chapter5\n",
      "say            0.482259\n",
      "caterpillar    0.460823\n",
      "pigeon         0.291569\n",
      "serpent        0.218677\n",
      "im             0.148111\n",
      "egg            0.145785\n",
      "youth          0.145785\n",
      "size           0.115815\n",
      "think          0.109989\n",
      "father         0.104335\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "chapter6\n",
      "say        0.420752\n",
      "cat        0.337845\n",
      "footman    0.227984\n",
      "baby       0.215375\n",
      "duchess    0.197076\n",
      "mad        0.190253\n",
      "pig        0.176216\n",
      "grin       0.155662\n",
      "sneeze     0.138366\n",
      "wow        0.136791\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "chapter7\n",
      "hatter      0.456682\n",
      "say         0.451985\n",
      "dormouse    0.420050\n",
      "hare        0.269002\n",
      "march       0.243921\n",
      "twinkle     0.145402\n",
      "time        0.111359\n",
      "draw        0.102477\n",
      "tea         0.099899\n",
      "know        0.098258\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "chapter8\n",
      "queen          0.483085\n",
      "say            0.379021\n",
      "gardeners      0.185272\n",
      "king           0.173467\n",
      "look           0.169350\n",
      "hedgehog       0.162113\n",
      "soldier        0.158123\n",
      "cat            0.157294\n",
      "head           0.129028\n",
      "executioner    0.115795\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "chapter9\n",
      "say        0.478602\n",
      "turtle     0.414016\n",
      "mock       0.398682\n",
      "gryphon    0.275268\n",
      "duchess    0.224643\n",
      "moral      0.161700\n",
      "queen      0.159533\n",
      "think      0.098536\n",
      "day        0.071079\n",
      "dont       0.070383\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "chapter10\n",
      "turtle       0.427697\n",
      "mock         0.386307\n",
      "gryphon      0.383891\n",
      "say          0.316633\n",
      "dance        0.272792\n",
      "beautiful    0.165560\n",
      "soup         0.165560\n",
      "lobster      0.127303\n",
      "lobsters     0.127303\n",
      "soooop       0.127303\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "chapter11\n",
      "king              0.410267\n",
      "hatter            0.369182\n",
      "say               0.338909\n",
      "court             0.298522\n",
      "dormouse          0.258719\n",
      "witness           0.231733\n",
      "queen             0.117580\n",
      "officer           0.115866\n",
      "begin             0.104900\n",
      "breadandbutter    0.099507\n",
      "Name: 10, dtype: float64\n",
      "\n",
      "chapter12\n",
      "say       0.476585\n",
      "king      0.402025\n",
      "jury      0.203591\n",
      "dream     0.184380\n",
      "write     0.165701\n",
      "queen     0.151296\n",
      "sister    0.138285\n",
      "rabbit    0.111054\n",
      "know      0.102793\n",
      "white     0.102249\n",
      "Name: 11, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chapter_num = 1\n",
    "index = list(range(1,11))\n",
    "for i in most_frequent_word:\n",
    "    most10 = most_frequent_word[:][i].nlargest(10)\n",
    "    print(\"chapter%d\"%(chapter_num))\n",
    "    chapter_num +=1\n",
    "    print(most10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "54466154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 verbs most related to alice : \n",
      "say \n",
      "think \n",
      "know \n",
      "come \n",
      "make \n",
      "begin \n",
      "run \n",
      "look \n",
      "tell \n",
      "happen \n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(textfile)\n",
    "sentences_with_alice = []\n",
    "verbs = ''\n",
    "for sentence in sentences:\n",
    "    preprocess_text = preprocess(sentence)\n",
    "    \n",
    "    if 'alice' in preprocess_text:\n",
    "        preprocess_text = re.sub(r'king', '', preprocess_text) \n",
    "        sentences_with_alice.append(preprocess_text)\n",
    "    else:\n",
    "        continue\n",
    "for sentence in sentences_with_alice:\n",
    "    s = nltk.pos_tag(sentence.split())\n",
    "    for w in s:\n",
    "        if 'VB' in w[1]:\n",
    "            verbs += w[0] + ' '\n",
    "        else:\n",
    "            continue\n",
    "response , feature_array = tfidf([verbs])\n",
    "\n",
    "tfidf_ranking = np.argsort(response.toarray()).flatten()[::-1]\n",
    "print(\"10 verbs most related to alice : \")\n",
    "for i in feature_array[tfidf_ranking][:10]:\n",
    "        print(\"%s \"%(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
